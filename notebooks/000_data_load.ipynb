{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **First Step**: \n",
    "1. The schema for the `spotify_staging` table is created based on `spotify_dataset.csv` for uploading to PostgreSQL using Render as a cloud service.\n",
    "2. The seed for the `spotify_staging` table is generated using the `spotify_dataset.csv` dataset.\n",
    "3. The existing table is dropped before creating a new one to avoid errors.\n",
    "4. The table is created in the Render PostgreSQL database.\n",
    "5. The data is inserted into the Render PostgreSQL instance.\n",
    "6. The table creation and data insertion are verified by checking the number of records in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Add the 'src' folder to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "#import previously created classes\n",
    "\n",
    "from connections.db import PostgreSQLConnection\n",
    "from utils.create_schema_seed import CreateSchemaSeed\n",
    "\n",
    "db_service = PostgreSQLConnection()\n",
    "schema_seed_service = CreateSchemaSeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating schema of spotify_staging\n",
      "✓ The SQL script has been successfully saved to ../sql/schema_spotify_staging.sql\n",
      "Creating seed of spotify_staging\n",
      "✓ The SQL script has been successfully saved to ../sql/seed_spotify_staging.sql\n"
     ]
    }
   ],
   "source": [
    "# Create the schema and seed for the spotify_staging table\n",
    "df_spotify_staging = pd.read_csv('../data/raw/spotify_dataset.csv')\n",
    "print('Creating schema of spotify_staging')\n",
    "print(schema_seed_service.infer_schema_postgres(df_spotify_staging, 'spotify_staging','../sql/schema_spotify_staging.sql'))\n",
    "print('Creating seed of spotify_staging')\n",
    "print(schema_seed_service.create_seed_postgres(df_spotify_staging, 'spotify_staging','../sql/seed_spotify_staging.sql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting spotify_staging table if it exists\n",
      "✓ Query executed successfully.\n"
     ]
    }
   ],
   "source": [
    "# We first delete the table if it exists to avoid errors.\n",
    "print(\"Deleting spotify_staging table if it exists\")\n",
    "print(db_service.run_query(db_service.open_query('../sql/queries/drop_table.sql', 'spotify_staging')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table spotify_staging\n",
      "✓ Query executed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create the spotify_staging table\n",
    "print(\"Creating table spotify_staging\")\n",
    "print(db_service.run_query(db_service.open_query('../sql/schema_spotify_staging.sql')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data into spotify_staging\n",
      "✓ Successfully inserted batch starting from query index 0.\n",
      "✓ Successfully inserted batch starting from query index 3000.\n",
      "✓ Successfully inserted batch starting from query index 6000.\n",
      "✓ Successfully inserted batch starting from query index 9000.\n",
      "✓ Successfully inserted batch starting from query index 12000.\n",
      "✓ Successfully inserted batch starting from query index 15000.\n",
      "✓ Successfully inserted batch starting from query index 18000.\n",
      "✓ Successfully inserted batch starting from query index 21000.\n",
      "✓ Successfully inserted batch starting from query index 24000.\n",
      "✓ Successfully inserted batch starting from query index 27000.\n",
      "✓ Successfully inserted batch starting from query index 30000.\n",
      "✓ Successfully inserted batch starting from query index 33000.\n",
      "✓ Successfully inserted batch starting from query index 36000.\n",
      "✓ Successfully inserted batch starting from query index 39000.\n",
      "✓ Successfully inserted batch starting from query index 42000.\n",
      "✓ Successfully inserted batch starting from query index 45000.\n",
      "✓ Successfully inserted batch starting from query index 48000.\n",
      "✓ Successfully inserted batch starting from query index 51000.\n",
      "✓ Successfully inserted batch starting from query index 54000.\n",
      "✓ Successfully inserted batch starting from query index 57000.\n",
      "✓ Successfully inserted batch starting from query index 60000.\n",
      "✓ Successfully inserted batch starting from query index 63000.\n",
      "✓ Successfully inserted batch starting from query index 66000.\n",
      "✓ Successfully inserted batch starting from query index 69000.\n",
      "✓ Successfully inserted batch starting from query index 72000.\n",
      "✓ Successfully inserted batch starting from query index 75000.\n",
      "✓ Successfully inserted batch starting from query index 78000.\n",
      "✓ Successfully inserted batch starting from query index 81000.\n",
      "✓ Successfully inserted batch starting from query index 84000.\n",
      "✓ Successfully inserted batch starting from query index 87000.\n",
      "✓ Successfully inserted batch starting from query index 90000.\n",
      "✓ Successfully inserted batch starting from query index 93000.\n",
      "✓ Successfully inserted batch starting from query index 96000.\n",
      "✓ Successfully inserted batch starting from query index 99000.\n",
      "✓ Successfully inserted batch starting from query index 102000.\n",
      "✓ Successfully inserted batch starting from query index 105000.\n",
      "✓ Successfully inserted batch starting from query index 108000.\n",
      "✓ Successfully inserted batch starting from query index 111000.\n",
      "✓ Data successfully inserted from SQL file.\n"
     ]
    }
   ],
   "source": [
    "#Insert the data to the spotify_staging table using the seed\n",
    "print(\"Inserting data into spotify_staging\")\n",
    "print(db_service.insert_data_from_sql('../sql/seed_spotify_staging.sql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying that the table has been created\n",
      "[('public.spotify_staging', 114000)]\n"
     ]
    }
   ],
   "source": [
    "# We verify that the table has been created.\n",
    "print(\"Verifying that the table has been created\")\n",
    "print(db_service.run_select_query(db_service.open_query('../sql/queries/list_tables.sql')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Second Step**:\n",
    "1. The schema for the `grammy_staging` table is created based on `spotify_dataset.csv` for uploading to PostgreSQL using Render as a cloud service.\n",
    "2. The seed for the `grammy_staging` table is generated using the `spotify_dataset.csv` dataset.\n",
    "3. The existing table is dropped before creating a new one to avoid errors.\n",
    "4. The table is created in the Render PostgreSQL database.\n",
    "5. The data is inserted into the Render PostgreSQL instance.\n",
    "6. The table creation and data insertion are verified by checking the number of records in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating schema of grammy_staging\n",
      "✓ The SQL script has been successfully saved to ../sql/schema_grammy_staging.sql\n",
      "Creating seed of grammy_staging\n",
      "✓ The SQL script has been successfully saved to ../sql/seed_grammy_staging.sql\n"
     ]
    }
   ],
   "source": [
    "# Create the schema and seed for the grammy_staging table\n",
    "df_spotify_staging = pd.read_csv('../data/raw/the_grammy_awards.csv')\n",
    "print('Creating schema of grammy_staging')\n",
    "print(schema_seed_service.infer_schema_postgres(df_spotify_staging, 'grammy_staging','../sql/schema_grammy_staging.sql'))\n",
    "print('Creating seed of grammy_staging')\n",
    "print(schema_seed_service.create_seed_postgres(df_spotify_staging, 'grammy_staging','../sql/seed_grammy_staging.sql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting grammy_staging table if it exists\n",
      "✓ Query executed successfully.\n"
     ]
    }
   ],
   "source": [
    "# We first delete the table if it exists to avoid errors.\n",
    "print(\"Deleting grammy_staging table if it exists\")\n",
    "print(db_service.run_query(db_service.open_query('../sql/queries/drop_table.sql', 'grammy_staging')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating table grammy_staging\n",
      "✓ Query executed successfully.\n"
     ]
    }
   ],
   "source": [
    "# We create the grammy_staging table\n",
    "print(\"Creating table grammy_staging\")\n",
    "print(db_service.run_query(db_service.open_query('../sql/schema_grammy_staging.sql')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data into grammy_staging\n",
      "✓ Successfully inserted batch starting from query index 0.\n",
      "✓ Successfully inserted batch starting from query index 3000.\n",
      "✓ Data successfully inserted from SQL file.\n"
     ]
    }
   ],
   "source": [
    "#Insert the data to the grammy_staging table using the seed\n",
    "print(\"Inserting data into grammy_staging\")\n",
    "print(db_service.insert_data_from_sql('../sql/seed_grammy_staging.sql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying that the table has been created\n",
      "[('public.spotify_staging', 114000), ('public.grammy_staging', 4810)]\n"
     ]
    }
   ],
   "source": [
    "# We verify that the table has been created.\n",
    "print(\"Verifying that the tables has been created\")\n",
    "print(db_service.run_select_query(db_service.open_query('../sql/queries/list_tables.sql')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "1. It was necessary to remove single quotes `' '` and double quotes `\" \"` from strings in the dataset to successfully upload the data.\n",
    "2. Some strings contained `;`, which caused errors by breaking the SQL query, so it had to be removed.\n",
    "3. PostgreSQL (and SQL in general) does not recognize `NaN` values, so it was essential to convert them to `NULL`.\n",
    "4. These changes were made to resolve issues encountered when uploading the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
